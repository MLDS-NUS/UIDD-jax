# Default config file for the linear case

temperature: 1
dt: 0.0005
dim: 3 # state dimension

Model_name: HD2


data:
  seed: 123 # random seed
  init_scale: 2.0 # scale of the initial condition
  var: 0.1
  t0: 0.0
  t1: 1
  num_runs: 10000 # number of training trajectories
  num_runs_test: 1000 # number of test trajectories

model:
  seed: 0
  # potential:
  #   alpha: 0.01 # regularization strength
  #   units: # layer sizes
  #     - 64
  #     - 64
  #   activation: "tanh"
  potential:
    activation: "srequ" # shifted ReQU activation
    alpha: 0.01 # regularization strength
    units: # layer sizes
      - 128
    n_pot: 32
  hamiltonian:
    units:
      - 128
      - 128
    activation: "tanh"
    is_bounded: false
  dissipation:
    alpha: 0.1
    units:
      - 32
      - 32
    activation: "tanh"
    is_bounded: false # whether to have the output bounded (via tanh activation)
  conservation:
    units:
      - 32
      - 32
    activation: "tanh"
    is_bounded: false
  diffusion:
    alpha: 0.001 

train:
  num_epochs: 2000
  batch_size: 2 # each batch will be [batch_size, train_traj_len, dim], so use a small batch size if train_traj_len is large
  train_traj_len: null # can shrink the length of the training trajectories for better GPU performance
  checkpoint_every: 200 # number of epochs to check-point the model
  print_every: 200 # number of epochs to print the loss
  opt: # optimiser options
    learning_rate: 1e-3
  rop: # reduce on plateau options
    patience: 20
    cooldown: 20
    factor: 0.4
    rtol: 1e-4
    min_scale: 1e-4
    accumulation_size: 2000
 
hydra:
  run:
    dir: ./outputs/main${model.seed}_${Model_name}
  sweep:
    dir: ./outputs/multirun/main${model.seed}_${Model_name}
    # dir: ./outputs/multirun/${now:%Y_%m_%d-%H_%M_%S}
    subdir: ${hydra.job.num}
  job:
    chdir: False  # 禁用目录切换，保证参数串行执行

